{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcbb2eed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mover_sampling\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomOverSampler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Flatten\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "le = LabelEncoder()\n",
    "oversample = RandomOverSampler()\n",
    "df = pd.read_csv('final_datasets/encoded_dataset.csv') #dataset\n",
    "X = df.iloc[:,3:]\n",
    "y = le.fit_transform(df['Streams'])\n",
    "#y = df.iloc[:, 2].values\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size = 0.2, random_state = 0)\n",
    "X_train=np.asarray(X_train).astype(np.int)\n",
    "y_train=tensorflow.one_hot(np.asarray(y_train).astype(np.int),depth=4)\n",
    "\n",
    "X_test=np.asarray(X_test).astype(np.int)\n",
    "y_test=tensorflow.one_hot(np.asarray(y_test).astype(np.int),depth=4)\n",
    "\n",
    "\n",
    "model = Sequential(name=\"ANN-for-resume-classification\")\n",
    "model.add(Input(shape=(1091,), name='Input-Layer'))\n",
    "model.add(Dense(512, activation='softplus', name='Hidden-Layer'))\n",
    "model.add(Dense(256, activation='softplus', name='Hidden-Layer-2'))\n",
    "model.add(Dense(16, activation='softplus', name='Hidden-Layer-3'))\n",
    "model.add(Dense(4, activation='sigmoid', name='Output-Layer'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=10,\n",
    "          epochs=12,\n",
    "          verbose='auto',\n",
    "         )\n",
    "\n",
    "\n",
    "pred_labels_tr = (model.predict(X_train) > 0.5).astype(int)\n",
    "pred_labels_te = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "model.summary()\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in model.layers:\n",
    "    print(\"Layer: \", layer.name)\n",
    "    print(\"  --Kernels (Weights): \", layer.get_weights()[0])\n",
    "    print(\"  --Biases: \", layer.get_weights()[1])\n",
    "\n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ea2312a96e00fc4424234a471f608c001e599e03afda339b55d660fc50d3e28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
