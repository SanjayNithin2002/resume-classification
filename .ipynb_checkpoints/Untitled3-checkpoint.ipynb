{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3d214a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Flatten\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import accuracy_score\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "fc88a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "feb59cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 81)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_datasets/encoded_dataset_clean_new.csv') #dataset\n",
    "data_train,data_test = split_train_test(df,0.2)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "95ae0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_var):\n",
    "    ans_ds = model_ds.predict(test_var)\n",
    "    ans_cc = model_cc.predict(test_var)\n",
    "    ans_cy = model_cy.predict(test_var)\n",
    "    ans_core = model_core.predict(test_var)\n",
    "    results = np.concatenate((ans_cc,ans_core,ans_cy,ans_ds),axis = 1)\n",
    "    results_ans = []\n",
    "    for i in results:\n",
    "        x = list(i)\n",
    "        x[0] = x[0]\n",
    "        x[1] = x[1]\n",
    "        x[2] = x[2]\n",
    "        x[3] = x[3]*0.9\n",
    "        results_ans+= [x.index(max(x))]\n",
    "    return results_ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c90a2219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9568\\271556961.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_test=np.asarray(X_test.iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9568\\271556961.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test=tensorflow.one_hot(np.asarray(y_test).astype(np.int),depth=4)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=20)\n",
    "le = LabelEncoder()\n",
    "#oversample = RandomOverSampler()\n",
    "#df = pd.read_csv('final_datasets/encoded_dataset_clean.csv') #dataset\n",
    "\n",
    "#df = pd.read_csv(\"data/proper_dataset.csv\")\n",
    "#X = df.iloc[:,2:]\n",
    "y = le.fit_transform(df['Streams'])\n",
    "#X, y= oversample.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = data_train.iloc[:,2:],data_test.iloc[:,2:],le.transform(data_train[\"Streams\"]),le.transform(data_test[\"Streams\"])\n",
    "X_test=np.asarray(X_test.iloc[:,1:]).astype(np.int)\n",
    "y_test=tensorflow.one_hot(np.asarray(y_test).astype(np.int),depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2664bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neuron = 78\n",
    "hidden_neuron1 = 32\n",
    "hidden_neuron2 = 32\n",
    "hidden_neuron3 = 32\n",
    "hidden_neuron4 = 32\n",
    "active_hidden = \"softplus\"\n",
    "active = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ff5ad23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9568\\3263981529.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_cc = np.asarray(X_train.loc[X_train['Streams']=='cloud computing'].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9568\\3263981529.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_cy = np.asarray(X_train.loc[X_train['Streams']=='cyber security'].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9568\\3263981529.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_core = np.asarray(X_train.loc[X_train['Streams']=='core'].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9568\\3263981529.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_ds = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6342 - Accuracy: 0.6548 - precision: 1.0000 - recall: 0.6548\n",
      "Epoch 2/12\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6202 - Accuracy: 0.7381 - precision: 1.0000 - recall: 0.7381\n",
      "Epoch 3/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6063 - Accuracy: 0.7857 - precision: 1.0000 - recall: 0.7857\n",
      "Epoch 4/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5927 - Accuracy: 0.8810 - precision: 1.0000 - recall: 0.8810\n",
      "Epoch 5/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5800 - Accuracy: 0.8810 - precision: 1.0000 - recall: 0.8810\n",
      "Epoch 6/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5673 - Accuracy: 0.8929 - precision: 1.0000 - recall: 0.8929\n",
      "Epoch 7/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5548 - Accuracy: 0.9167 - precision: 1.0000 - recall: 0.9167\n",
      "Epoch 8/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5431 - Accuracy: 0.9524 - precision: 1.0000 - recall: 0.9524\n",
      "Epoch 9/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5318 - Accuracy: 0.9524 - precision: 1.0000 - recall: 0.9524\n",
      "Epoch 10/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5204 - Accuracy: 0.9524 - precision: 1.0000 - recall: 0.9524\n",
      "Epoch 11/12\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5098 - Accuracy: 0.9643 - precision: 1.0000 - recall: 0.9643\n",
      "Epoch 12/12\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4992 - Accuracy: 0.9643 - precision: 1.0000 - recall: 0.9643\n",
      "Epoch 1/12\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6873 - Accuracy: 0.8056 - precision: 1.0000 - recall: 0.8056\n",
      "Epoch 2/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6826 - Accuracy: 0.9167 - precision: 1.0000 - recall: 0.9167\n",
      "Epoch 3/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6779 - Accuracy: 0.9167 - precision: 1.0000 - recall: 0.9167\n",
      "Epoch 4/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6733 - Accuracy: 0.9167 - precision: 1.0000 - recall: 0.9167\n",
      "Epoch 5/12\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6687 - Accuracy: 0.9583 - precision: 1.0000 - recall: 0.9583\n",
      "Epoch 6/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6643 - Accuracy: 0.9583 - precision: 1.0000 - recall: 0.9583\n",
      "Epoch 7/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6598 - Accuracy: 0.9583 - precision: 1.0000 - recall: 0.9583\n",
      "Epoch 8/12\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6554 - Accuracy: 0.9583 - precision: 1.0000 - recall: 0.9583\n",
      "Epoch 9/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6510 - Accuracy: 0.9583 - precision: 1.0000 - recall: 0.9583\n",
      "Epoch 10/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6466 - Accuracy: 0.9583 - precision: 1.0000 - recall: 0.9583\n",
      "Epoch 11/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6423 - Accuracy: 0.9722 - precision: 1.0000 - recall: 0.9722\n",
      "Epoch 12/12\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6380 - Accuracy: 0.9722 - precision: 1.0000 - recall: 0.9722\n",
      "Epoch 1/12\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7499 - Accuracy: 0.4138 - precision: 1.0000 - recall: 0.4138\n",
      "Epoch 2/12\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.7438 - Accuracy: 0.4138 - precision: 1.0000 - recall: 0.4138\n",
      "Epoch 3/12\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7378 - Accuracy: 0.4483 - precision: 1.0000 - recall: 0.4483\n",
      "Epoch 4/12\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7320 - Accuracy: 0.4483 - precision: 1.0000 - recall: 0.4483\n",
      "Epoch 5/12\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7263 - Accuracy: 0.4483 - precision: 1.0000 - recall: 0.4483\n",
      "Epoch 6/12\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7205 - Accuracy: 0.4483 - precision: 1.0000 - recall: 0.4483\n",
      "Epoch 7/12\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7152 - Accuracy: 0.4483 - precision: 1.0000 - recall: 0.4483\n",
      "Epoch 8/12\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7094 - Accuracy: 0.5172 - precision: 1.0000 - recall: 0.5172\n",
      "Epoch 9/12\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7043 - Accuracy: 0.5172 - precision: 1.0000 - recall: 0.5172\n",
      "Epoch 10/12\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6985 - Accuracy: 0.5517 - precision: 1.0000 - recall: 0.5517\n",
      "Epoch 11/12\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6932 - Accuracy: 0.5862 - precision: 1.0000 - recall: 0.5862\n",
      "Epoch 12/12\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6878 - Accuracy: 0.5862 - precision: 1.0000 - recall: 0.5862\n",
      "Epoch 1/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7218 - Accuracy: 0.4296 - precision: 1.0000 - recall: 0.4296\n",
      "Epoch 2/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6970 - Accuracy: 0.4963 - precision: 1.0000 - recall: 0.4963\n",
      "Epoch 3/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6728 - Accuracy: 0.5556 - precision: 1.0000 - recall: 0.5556\n",
      "Epoch 4/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6500 - Accuracy: 0.6148 - precision: 1.0000 - recall: 0.6148\n",
      "Epoch 5/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6278 - Accuracy: 0.6815 - precision: 1.0000 - recall: 0.6815\n",
      "Epoch 6/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6068 - Accuracy: 0.7111 - precision: 1.0000 - recall: 0.7111\n",
      "Epoch 7/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5868 - Accuracy: 0.7481 - precision: 1.0000 - recall: 0.7481\n",
      "Epoch 8/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5674 - Accuracy: 0.7630 - precision: 1.0000 - recall: 0.7630\n",
      "Epoch 9/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5490 - Accuracy: 0.8074 - precision: 1.0000 - recall: 0.8074\n",
      "Epoch 10/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5315 - Accuracy: 0.8963 - precision: 1.0000 - recall: 0.8963\n",
      "Epoch 11/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5147 - Accuracy: 0.9481 - precision: 1.0000 - recall: 0.9481\n",
      "Epoch 12/12\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4987 - Accuracy: 0.9778 - precision: 1.0000 - recall: 0.9778\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "+--------------+--------------+--------------+--------------+-----------------+\n",
      "|      cc      |     core     |      cy      |      ds      |       ans       |\n",
      "+--------------+--------------+--------------+--------------+-----------------+\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "|  [0.60527]   | [0.50179875] | [0.5724387]  | [0.5425925]  |  cyber security |\n",
      "| [0.5931775]  | [0.6602014]  | [0.3892627]  | [0.7121365]  |   data science  |\n",
      "| [0.5494015]  | [0.55650055] | [0.47916964] | [0.5165787]  |   data science  |\n",
      "| [0.60268784] | [0.56487846] | [0.5657018]  | [0.59308165] |   data science  |\n",
      "| [0.4872883]  | [0.45154086] | [0.5864655]  | [0.64636177] |   data science  |\n",
      "| [0.5494015]  | [0.55650055] | [0.47916964] | [0.5165787]  |   data science  |\n",
      "| [0.6466155]  | [0.5669838]  | [0.54253024] | [0.6011019]  | cloud computing |\n",
      "| [0.5363313]  | [0.5622234]  | [0.55826867] | [0.5402422]  | cloud computing |\n",
      "| [0.48499468] | [0.57487744] | [0.46732837] | [0.5544768]  | cloud computing |\n",
      "| [0.6236985]  | [0.63133126] | [0.56275195] | [0.55506355] | cloud computing |\n",
      "| [0.5554544]  | [0.5916158]  | [0.5163956]  | [0.53063416] | cloud computing |\n",
      "| [0.58383703] | [0.62809867] | [0.41727903] | [0.55370873] |  cyber security |\n",
      "| [0.48999736] | [0.44148564] | [0.64394563] | [0.78291684] |   data science  |\n",
      "|  [0.595224]  | [0.5089852]  | [0.5162523]  | [0.49939388] | cloud computing |\n",
      "| [0.60984594] | [0.65716445] | [0.50194675] | [0.52413607] |       core      |\n",
      "| [0.5201955]  | [0.52601993] | [0.4562779]  | [0.6145466]  |   data science  |\n",
      "| [0.47877848] |  [0.590039]  | [0.5429557]  | [0.59148514] |  cyber security |\n",
      "| [0.56911457] | [0.6596604]  | [0.4848494]  | [0.56459004] |   data science  |\n",
      "| [0.52508825] | [0.6192792]  | [0.45819038] | [0.55978435] |  cyber security |\n",
      "| [0.5696389]  | [0.57691664] | [0.5120495]  | [0.5406974]  |   data science  |\n",
      "| [0.5495242]  | [0.5134357]  | [0.60997534] | [0.6026511]  |   data science  |\n",
      "| [0.5245288]  | [0.53203934] | [0.6093321]  | [0.5794107]  | cloud computing |\n",
      "| [0.6030471]  | [0.4210954]  | [0.5341029]  | [0.6556119]  |   data science  |\n",
      "| [0.64313865] | [0.6042749]  | [0.39004177] | [0.5262516]  | cloud computing |\n",
      "| [0.60866964] | [0.45621744] | [0.57669044] | [0.53551185] | cloud computing |\n",
      "| [0.5363313]  | [0.5622234]  | [0.55826867] | [0.5402422]  |       core      |\n",
      "| [0.60866964] | [0.45621744] | [0.57669044] | [0.53551185] | cloud computing |\n",
      "|  [0.511525]  | [0.5947108]  | [0.41729122] | [0.6037738]  |  cyber security |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.59999704] | [0.6214233]  | [0.45249796] | [0.5232709]  |  cyber security |\n",
      "| [0.52023727] | [0.5840867]  | [0.63910544] | [0.6453826]  |   data science  |\n",
      "| [0.5595817]  | [0.59437025] | [0.5287185]  | [0.5174448]  | cloud computing |\n",
      "| [0.60137707] | [0.39428836] | [0.4825738]  | [0.6601423]  |  cyber security |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "|  [0.54511]   | [0.4333242]  | [0.5121742]  | [0.4536708]  |       core      |\n",
      "| [0.6159357]  | [0.5520281]  | [0.57077396] | [0.6529291]  | cloud computing |\n",
      "| [0.44167903] | [0.62192315] | [0.2841321]  | [0.77784616] |  cyber security |\n",
      "| [0.47271773] | [0.4120927]  | [0.57246554] | [0.55756634] |  cyber security |\n",
      "| [0.5906464]  | [0.5695812]  | [0.5128773]  | [0.54354715] |  cyber security |\n",
      "| [0.5820551]  | [0.51582867] | [0.5010481]  | [0.61474085] |   data science  |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.5376449]  | [0.5262544]  | [0.5317068]  | [0.5561067]  |   data science  |\n",
      "| [0.58000505] | [0.5322338]  | [0.59471065] | [0.61496466] |       core      |\n",
      "| [0.45092615] | [0.47773716] | [0.4598882]  | [0.7486001]  |   data science  |\n",
      "|  [0.514686]  | [0.5467964]  | [0.41203275] |  [0.612382]  |   data science  |\n",
      "| [0.7410372]  | [0.5246303]  | [0.39903998] | [0.77298903] |   data science  |\n",
      "| [0.5363313]  | [0.5622234]  | [0.55826867] | [0.5402422]  | cloud computing |\n",
      "| [0.60866964] | [0.45621744] | [0.57669044] | [0.53551185] | cloud computing |\n",
      "| [0.60410887] | [0.55611455] |  [0.513971]  | [0.6372118]  |   data science  |\n",
      "| [0.6338309]  | [0.38085043] | [0.5775935]  | [0.71191764] |  cyber security |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.60142195] |  [0.600143]  | [0.5918157]  | [0.5775347]  | cloud computing |\n",
      "| [0.5311075]  | [0.55645496] | [0.4848629]  | [0.53517824] |   data science  |\n",
      "| [0.46850455] | [0.5520698]  | [0.49346972] | [0.59064674] |  cyber security |\n",
      "| [0.5905033]  | [0.52872586] | [0.46725503] | [0.74191284] |   data science  |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.51545554] | [0.57519275] | [0.4749335]  | [0.49277055] |       core      |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.60224885] | [0.58838665] | [0.58638173] | [0.63523376] |   data science  |\n",
      "| [0.56858873] | [0.57869846] | [0.46863875] | [0.5981832]  |   data science  |\n",
      "| [0.5494015]  | [0.55650055] | [0.47916964] | [0.5165787]  |   data science  |\n",
      "| [0.5627712]  | [0.52334446] | [0.60961187] | [0.5877195]  |  cyber security |\n",
      "| [0.5554412]  | [0.43891335] | [0.48723885] | [0.75968754] |   data science  |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.5447391]  | [0.57691646] | [0.6227234]  | [0.67832345] |   data science  |\n",
      "| [0.63078976] | [0.48907453] | [0.5473734]  | [0.5126915]  | cloud computing |\n",
      "| [0.5157667]  | [0.5453981]  | [0.5348706]  | [0.5601521]  |   data science  |\n",
      "| [0.6187593]  | [0.62586755] | [0.48940986] | [0.55002683] | cloud computing |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.57780373] | [0.5719321]  | [0.49969637] | [0.56562763] |   data science  |\n",
      "| [0.5494015]  | [0.55650055] | [0.47916964] | [0.5165787]  |   data science  |\n",
      "| [0.54341364] | [0.49942723] | [0.5003552]  | [0.5136535]  | cloud computing |\n",
      "| [0.4717999]  | [0.49176717] | [0.5317747]  | [0.5588455]  |   data science  |\n",
      "| [0.54151237] | [0.48340312] | [0.56411284] | [0.62818927] |   data science  |\n",
      "| [0.5494015]  | [0.55650055] | [0.47916964] | [0.5165787]  |       core      |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.41967282] |  [0.67291]   | [0.48433432] | [0.7258442]  |   data science  |\n",
      "| [0.5260689]  | [0.5237572]  | [0.5089412]  | [0.5393806]  |       core      |\n",
      "| [0.5142418]  | [0.4933112]  | [0.5612251]  | [0.57856524] |   data science  |\n",
      "+--------------+--------------+--------------+--------------+-----------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "X_train_cc = np.asarray(X_train.loc[X_train['Streams']=='cloud computing'].iloc[:,1:]).astype(np.int)\n",
    "X_train_cy = np.asarray(X_train.loc[X_train['Streams']=='cyber security'].iloc[:,1:]).astype(np.int)\n",
    "X_train_core = np.asarray(X_train.loc[X_train['Streams']=='core'].iloc[:,1:]).astype(np.int)\n",
    "X_train_ds = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n",
    "\n",
    "#X_train_cc = (pca.fit(X_train_cc)).singular_values_\n",
    "#X_train_core = (pca.fit(X_train_core)).singular_values_\n",
    "#X_train_cy = (pca.fit(X_train_cy)).singular_values_\n",
    "#X_train_ds = (pca.fit(X_train_ds)).singular_values_\n",
    "\n",
    "\n",
    "y_train_cc = np.broadcast_to(np.array([1]), (X_train_cc.shape[0], 1))\n",
    "y_train_core = np.broadcast_to(np.array([1]), (X_train_core.shape[0], 1))\n",
    "y_train_cy = np.broadcast_to(np.array([1]), (X_train_cy.shape[0], 1))\n",
    "y_train_ds = np.broadcast_to(np.array([1]), (X_train_ds.shape[0], 1))\n",
    "\n",
    "y_test_cc = np.array([[1] if list(i) == [1,0,0,0] else [0] for i in y_test])\n",
    "y_test_core = np.array([[1] if list(i) == [0,1,0,0] else [0] for i in y_test])\n",
    "y_test_cy = np.array([[1] if list(i) == [0,0,1,0] else [0] for i in y_test])\n",
    "y_test_ds = np.array([[1] if list(i) == [0,0,0,1] else [0] for i in y_test])\n",
    "\n",
    "model_cc = Sequential(name=\"ANN-for-resume-classification-cc\")   \n",
    "model_cc.add(Input(shape=(input_neuron,), name='Input-Layer'))\n",
    "#model_cc.add(Dense(hidden_neuron1, activation=active_hidden, name='Hidden-Layer'))\n",
    "#model_cc.add(Dense(8, activation='softplus', name='Hidden-Layer-2'))\n",
    "#model_cc.add(Dense(4, activation='softplus', name='Hidden-Layer-3'))\n",
    "model_cc.add(Dense(1, activation=active, name='Output-Layer'))\n",
    "\n",
    "\n",
    "model_cc.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model_cc.fit(X_train_cc,\n",
    "          y_train_cc,\n",
    "          batch_size=10,\n",
    "          epochs=12,\n",
    "          verbose='auto',\n",
    "         )\n",
    "\n",
    "\n",
    "model_core = Sequential(name=\"ANN-for-resume-classification-core\")\n",
    "model_core.add(Input(shape=(input_neuron,), name='Input-Layer'))\n",
    "#model_core.add(Dense(hidden_neuron2, activation=active_hidden, name='Hidden-Layer'))\n",
    "#model_core.add(Dense(8, activation='softplus', name='Hidden-Layer-2'))\n",
    "#model_core.add(Dense(4, activation='softplus', name='Hidden-Layer-3'))\n",
    "model_core.add(Dense(1, activation=active, name='Output-Layer'))\n",
    "\n",
    "\n",
    "model_core.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model_core.fit(X_train_core,\n",
    "          y_train_core,\n",
    "          batch_size=10,\n",
    "          epochs=12,\n",
    "          verbose='auto',\n",
    "         )\n",
    "\n",
    "model_cy = Sequential(name=\"ANN-for-resume-classification-cy\")\n",
    "model_cy.add(Input(shape=(input_neuron,), name='Input-Layer'))\n",
    "#model_cy.add(Dense(hidden_neuron3, activation=active_hidden, name='Hidden-Layer'))\n",
    "#model_cy.add(Dense(8, activation='softplus', name='Hidden-Layer-2'))\n",
    "#model_cy.add(Dense(4, activation='softplus', name='Hidden-Layer-3'))\n",
    "model_cy.add(Dense(1, activation=active, name='Output-Layer'))\n",
    "\n",
    "\n",
    "model_cy.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model_cy.fit(X_train_cy,\n",
    "          y_train_cy,\n",
    "          batch_size=10,\n",
    "          epochs=12,\n",
    "          verbose='auto',\n",
    "         )\n",
    "\n",
    "model_ds = Sequential(name=\"ANN-for-resume-classification-ds\")\n",
    "model_ds.add(Input(shape=(input_neuron,), name='Input-Layer'))\n",
    "#model_ds.add(Dense(hidden_neuron4, activation=active_hidden, name='Hidden-Layer'))\n",
    "#model_ds.add(Dense(8, activation='softplus', name='Hidden-Layer-2'))\n",
    "#model_ds.add(Dense(4, activation='softplus', name='Hidden-Layer-3'))\n",
    "model_ds.add(Dense(1, activation=active, name='Output-Layer'))\n",
    "\n",
    "\n",
    "model_ds.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model_ds.fit(X_train_ds,\n",
    "          y_train_ds,\n",
    "          batch_size=10,\n",
    "          epochs=12,\n",
    "          verbose='auto',\n",
    "         )\n",
    "         \n",
    "\n",
    "\n",
    "ans_ds = model_ds.predict(X_test)\n",
    "ans_cc = model_cc.predict(X_test)\n",
    "ans_cy = model_cy.predict(X_test)\n",
    "ans_core = model_core.predict(X_test)\n",
    "ans = []\n",
    "for i in y_test:\n",
    "    x = list(i)\n",
    "    if x == [1,0,0,0]:\n",
    "        ans.append(\"cloud computing\")\n",
    "    if x == [0,1,0,0]:\n",
    "        ans.append(\"core\")\n",
    "    if x == [0,0,1,0]:\n",
    "        ans.append(\"cyber security\")\n",
    "    if x == [0,0,0,1]:\n",
    "        ans.append(\"data science\")\n",
    "table = PrettyTable()\n",
    "table.add_column(\"cc\", ans_cc)\n",
    "table.add_column(\"core\", ans_core)\n",
    "table.add_column(\"cy\", ans_cy)\n",
    "table.add_column(\"ds\", ans_ds)\n",
    "table.add_column(\"ans\", ans)\n",
    "print(table)\n",
    "ans = []\n",
    "for i in y_test:\n",
    "    x = list(i)\n",
    "    if x == [1,0,0,0]:\n",
    "        ans.append(0)\n",
    "    if x == [0,1,0,0]:\n",
    "        ans.append(1)\n",
    "    if x == [0,0,1,0]:\n",
    "        ans.append(2)\n",
    "    if x == [0,0,0,1]:\n",
    "        ans.append(3)\n",
    "\n",
    "y_pred = model_predict(X_test)\n",
    "score = accuracy_score(ans, y_pred,normalize = True)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5f99e4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2875\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e6b8ddf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a60383ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35dbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# y = 1 * x_0 + 2 * x_1 + 3\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
